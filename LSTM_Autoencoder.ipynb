{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo-6dhL1HMOz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/235Kaggle/235kaggle'\n",
        "import os\n",
        "os.listdir(data_folder)\n",
        "\n",
        "import pandas as pd\n",
        "def read_csv(file_name):\n",
        "  return pd.read_csv(os.path.join(data_folder, file_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(data_folder)"
      ],
      "metadata": {
        "id": "bsxKVyz7RlXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logon = read_csv('logon.csv')\n",
        "logon.head()\n",
        "\n",
        "emails = read_csv('email.csv')\n",
        "emails.head()\n",
        "\n",
        "files = read_csv('file.csv')\n",
        "files.head()\n",
        "\n",
        "decoys = read_csv('decoy_file.csv')\n",
        "decoys.head()\n",
        "\n",
        "device = read_csv('device.csv')\n",
        "display(device.head())\n",
        "\n",
        "psychometric = read_csv('psychometric.csv')\n",
        "display(psychometric.head())\n",
        "\n",
        "insiders = read_csv('insiders.csv')\n",
        "display(insiders.head())"
      ],
      "metadata": {
        "id": "USeChAS8RyT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logon_df  = logon.copy()\n",
        "device_df = device.copy()\n",
        "email_df  = emails.copy()\n",
        "\n",
        "logon_df['date']  = pd.to_datetime(logon_df['date'])\n",
        "device_df['date'] = pd.to_datetime(device_df['date'])\n",
        "email_df['date']  = pd.to_datetime(email_df['date'])\n",
        "\n",
        "for df in [logon_df, device_df, email_df]:\n",
        "    df['day']            = df['date'].dt.date\n",
        "    df['hour']           = df['date'].dt.hour\n",
        "    df['is_after_hours'] = (df['hour'] < 6) | (df['hour'] >= 18)\n",
        "    df['is_weekend']     = df['date'].dt.dayofweek >= 5\n",
        "\n",
        "print(\"Date parsing complete.\")\n"
      ],
      "metadata": {
        "id": "1jhlKZCtSd0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_users = set(logon_df['user'].unique())\n",
        "print(f\"Total unique users: {len(all_users)}\")\n",
        "\n",
        "user_pc_counts = logon_df.groupby(['user','pc']).size().reset_index(name='count')\n",
        "user_primary_pc = user_pc_counts.loc[user_pc_counts.groupby('user')['count'].idxmax()]\n",
        "user_primary_pc = dict(zip(user_primary_pc['user'], user_primary_pc['pc']))\n",
        "\n",
        "print(\"User-PC mapping complete.\")\n"
      ],
      "metadata": {
        "id": "r51M4h6wSlF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logon aggregates\n",
        "logon_agg = logon_df[logon_df['activity']==\"Logon\"].groupby(['user','day']).agg(\n",
        "    logon_count        = ('id','count'),\n",
        "    after_hours_logons = ('is_after_hours','sum'),\n",
        "    unique_pcs         = ('pc','nunique')\n",
        ").reset_index()\n",
        "\n",
        "# Foreign PC logons\n",
        "logon_df['is_primary_pc'] = logon_df.apply(\n",
        "    lambda x: x['pc'] == user_primary_pc.get(x['user'],''), axis=1\n",
        ")\n",
        "\n",
        "foreign_logons = (\n",
        "    logon_df[(logon_df['activity']==\"Logon\") & (~logon_df['is_primary_pc'])]\n",
        "    .groupby(['user','day']).size().reset_index(name='foreign_pc_logons')\n",
        ")\n",
        "\n",
        "# Device aggregates\n",
        "device_agg = device_df[device_df['activity']==\"Connect\"].groupby(['user','day']).agg(\n",
        "    device_connects    = ('id','count'),\n",
        "    after_hours_device = ('is_after_hours','sum')\n",
        ").reset_index()\n",
        "\n",
        "# Email aggregates\n",
        "def count_recipients(row):\n",
        "    total = 0\n",
        "    for col in ['to','cc','bcc']:\n",
        "        if col in row and pd.notna(row[col]) and row[col]:\n",
        "            total += len(str(row[col]).split(';'))\n",
        "    return total\n",
        "\n",
        "email_df['recipient_count'] = email_df.apply(count_recipients, axis=1)\n",
        "email_sent = email_df[email_df['activity']==\"Send\"]\n",
        "\n",
        "email_agg = email_sent.groupby(['user','day']).agg(\n",
        "    emails_sent      = ('id','count'),\n",
        "    max_recipients   = ('recipient_count','max'),\n",
        "    total_recipients = ('recipient_count','sum'),\n",
        "    avg_recipients   = ('recipient_count','mean')\n",
        ").reset_index()\n",
        "\n",
        "print(\"Daily feature aggregation complete.\")\n"
      ],
      "metadata": {
        "id": "pA0EldrJS15A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df = logon_agg.copy()\n",
        "\n",
        "features_df = features_df.merge(foreign_logons, on=['user','day'], how='left')\n",
        "features_df = features_df.merge(device_agg,    on=['user','day'], how='left')\n",
        "features_df = features_df.merge(email_agg,     on=['user','day'], how='left')\n",
        "\n",
        "features_df = features_df.fillna(0)\n",
        "features_df['day'] = pd.to_datetime(features_df['day'])\n",
        "features_df = features_df.sort_values(['user','day']).reset_index(drop=True)\n",
        "\n",
        "print(\"FEATURE MATRIX SHAPE:\", features_df.shape)\n",
        "features_df.head()\n"
      ],
      "metadata": {
        "id": "bcFRPFMBTpEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "HP3terbTUti0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [\n",
        "    'logon_count',\n",
        "    'after_hours_logons',\n",
        "    'unique_pcs',\n",
        "    'foreign_pc_logons',\n",
        "    'device_connects',\n",
        "    'after_hours_device',\n",
        "    'emails_sent',\n",
        "    'max_recipients',\n",
        "    'total_recipients',\n",
        "    'avg_recipients'\n",
        "]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(features_df[feature_cols])\n",
        "\n",
        "features_scaled = features_df.copy()\n",
        "features_scaled[feature_cols] = scaler.transform(features_scaled[feature_cols])\n",
        "\n",
        "features_scaled.head()\n"
      ],
      "metadata": {
        "id": "EjLT2jRaUkNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "aecOiWhZV7Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We take a 30 day rolling window\n",
        "SEQ_LENGTH = 30\n",
        "\n",
        "def generate_seq(df_scaled, feature_cols, seq_len=SEQ_LENGTH):\n",
        "    X_list = []\n",
        "    meta_rows = []\n",
        "\n",
        "    for user, user_df in df_scaled.groupby('user'):\n",
        "        user_df = user_df.sort_values('day')\n",
        "        vals = user_df[feature_cols].values\n",
        "        days = user_df['day'].values\n",
        "\n",
        "        if len(vals) < seq_len:\n",
        "            continue\n",
        "\n",
        "        for start in range(len(vals) - seq_len + 1):\n",
        "            end = start + seq_len\n",
        "            X_list.append(vals[start:end])\n",
        "            meta_rows.append({'user': user, 'day': days[end-1]})\n",
        "\n",
        "    return np.array(X_list), pd.DataFrame(meta_rows)\n",
        "\n",
        "X_train, meta_train = generate_seq(features_scaled, feature_cols)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "meta_train.head()\n"
      ],
      "metadata": {
        "id": "jBo2g3CnVyVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "metadata": {
        "id": "R2WINegUXXiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_steps = SEQ_LENGTH\n",
        "features_N = len(feature_cols)\n",
        "\n",
        "inputs = Input(shape=(t_steps, features_N))\n",
        "x = LSTM(64, return_sequences=True)(inputs)\n",
        "x = LSTM(32, return_sequences=False)(x)\n",
        "\n",
        "x = RepeatVector(t_steps)(x)\n",
        "x = LSTM(64, return_sequences=True)(x)\n",
        "outputs = TimeDistributed(Dense(features_N))(x)\n",
        "\n",
        "LSTM_AUENCO = Model(inputs, outputs)\n",
        "LSTM_AUENCO.compile(optimizer='adam', loss='mse')\n",
        "LSTM_AUENCO.summary()\n"
      ],
      "metadata": {
        "id": "HGbpJ3q6XBDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ],
      "metadata": {
        "id": "3_xpfqhVX9-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = LSTM_AUENCO.fit(\n",
        "    X_train, X_train,\n",
        "    epochs=20,\n",
        "    batch_size=256,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,\n",
        "    callbacks=[stopping],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "_QZDaXjyXxKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_x, all_META = generate_seq(features_scaled, feature_cols)\n",
        "print(\"X_all shape:\", all_x.shape)\n"
      ],
      "metadata": {
        "id": "K_-Bpm5YqxIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_all_pred = LSTM_AUENCO.predict(all_x, batch_size=256, verbose=1)\n",
        "\n",
        "recon_errors = np.mean((all_x - X_all_pred)**2, axis=(1,2))\n",
        "all_META['recon_error'] = recon_errors\n",
        "\n",
        "all_META.head()\n"
      ],
      "metadata": {
        "id": "JalYLI_Tq57M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_sco = (\n",
        "    all_META.groupby(['user','day'])\n",
        "            .agg(lstm_error=('recon_error','max'))\n",
        "            .reset_index()\n",
        ")\n",
        "\n",
        "daily_sco['lstm_rank'] = daily_sco['lstm_error'].rank(ascending=False)\n",
        "daily_sco['lstm_percentile'] = daily_sco['lstm_error'].rank(pct=True)\n",
        "\n",
        "print(daily_sco.head())\n"
      ],
      "metadata": {
        "id": "3esD-C4PsA1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_feat = features_df.merge(daily_sco, on=['user','day'], how='left')\n",
        "lstm_feat['lstm_error']      = lstm_feat['lstm_error'].fillna(0)\n",
        "lstm_feat['lstm_rank']       = lstm_feat['lstm_rank'].fillna(lstm_feat['lstm_rank'].max()+1)\n",
        "lstm_feat['lstm_percentile'] = lstm_feat['lstm_percentile'].fillna(0)\n",
        "\n",
        "lstm_feat.head()\n"
      ],
      "metadata": {
        "id": "ncrhgrA0sIEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3_user = \"PLJ1771\"\n",
        "s3_day  = pd.to_datetime(\"2010-08-12\")\n",
        "\n",
        "s3_row = lstm_feat[\n",
        "    (lstm_feat['user']==s3_user) &\n",
        "    (lstm_feat['day']==s3_day)\n",
        "]\n",
        "\n",
        "display(s3_row)\n",
        "\n",
        "if len(s3_row):\n",
        "    row = s3_row.iloc[0]\n",
        "    print(\"\\nScenario 3 Evaluation:\")\n",
        "    print(\"User:\", s3_user, \"| Attack day:\", s3_day.date())\n",
        "    print(\"LSTM Error:\", row['lstm_error'])\n",
        "    print(\"Rank (1 = most anomalous):\", int(row['lstm_rank']))\n",
        "    print(\"Percentile:\", round(row['lstm_percentile'],4))\n",
        "else:\n",
        "    print(\"Scenario 3 row not found.\")\n"
      ],
      "metadata": {
        "id": "PhkKnarvsMD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3_user = \"PLJ1771\"\n",
        "s3_day  = pd.to_datetime(\"2010-08-12\")\n",
        "\n",
        "s3_row = lstm_feat[\n",
        "    (lstm_feat['user']==s3_user) &\n",
        "    (lstm_feat['day']==s3_day)\n",
        "][['user','day','lstm_rank','lstm_percentile']]\n",
        "\n",
        "display(s3_row)\n"
      ],
      "metadata": {
        "id": "6UxiJsmhtwbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    scenario4_users = insiders[insiders['scenario']==4]['user'].unique().tolist()\n",
        "except:\n",
        "    scenario4_users = []\n"
      ],
      "metadata": {
        "id": "D7Ach4-5sUAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(scenario4_users):\n",
        "    s4_rows = lstm_feat[lstm_feat['user'].isin(scenario4_users)]\n",
        "    s4_top = s4_rows.sort_values('lstm_error', ascending=False).head(20)\n",
        "    print(\"Top Scenario 4 anomalies:\")\n",
        "    display(s4_top[['user','day','lstm_rank','lstm_percentile']])\n",
        "else:\n",
        "    print(\"Scenario 4 insiders not provided.\")\n"
      ],
      "metadata": {
        "id": "VKhhzLRqsW4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def gen_plots(lstm_feat, user_id):\n",
        "\n",
        "    user_df = (\n",
        "        lstm_feat[lstm_feat['user'] == user_id]\n",
        "        .sort_values('day')\n",
        "        .copy()\n",
        "    )\n",
        "\n",
        "\n",
        "    err = user_df['lstm_error'].values\n",
        "    err_scaled = (err - err.min()) / (err.max() - err.min() + 1e-12)\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 4))\n",
        "    ax.plot(user_df['day'], err_scaled, marker='o', markersize=3, linewidth=1)\n",
        "\n",
        "    ax.set_title(f\"Anomaly scores over time — {user_id}\")\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    ax.set_ylabel(\"Scaled LSTM error (0–1)\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "\n",
        "    fig.autofmt_xdate()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "gen_plots(lstm_feat, \"PLJ1771\")\n",
        "gen_plots(lstm_feat, \"CDE1846\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FCw5nz2Bwxg2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}