{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvXdqmH-Dzo_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18zAO9DPEEH3"
      },
      "outputs": [],
      "source": [
        "data_folder = '/content/drive/MyDrive/235kaggle'\n",
        "import os\n",
        "os.listdir(data_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2Z_9a3BSLCX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def read_csv(file_name, parse_dates=None):\n",
        "    return pd.read_csv(os.path.join(data_folder, file_name), parse_dates=parse_dates)\n",
        "\n",
        "logon = read_csv('logon.csv', parse_dates=[\"date\"])\n",
        "devices = read_csv('device.csv', parse_dates=[\"date\"])\n",
        "emails = read_csv('email.csv', parse_dates=[\"date\"])\n",
        "files = read_csv('file.csv', parse_dates=[\"date\"])\n",
        "\n",
        "print(\"Logon shape:\", logon.shape)\n",
        "print(\"Devices shape:\", devices.shape)\n",
        "print(\"Emails shape:\", emails.shape)\n",
        "print(\"Files shape:\", files.shape)\n",
        "\n",
        "display(logon.head())\n",
        "display(devices.head())\n",
        "display(emails.head())\n",
        "display(files.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQA7CvvWF128"
      },
      "outputs": [],
      "source": [
        "# date ranges\n",
        "print(\"\\nLogon date range:\", logon[\"date\"].min(), \"->\", logon[\"date\"].max())\n",
        "print(\"Device date range:\", devices[\"date\"].min(), \"->\", devices[\"date\"].max())\n",
        "\n",
        "# logon events by hour of day\n",
        "logon[\"hour\"] = logon[\"date\"].dt.hour\n",
        "\n",
        "# activity distribution\n",
        "plt.figure(figsize=(8, 4))\n",
        "logon[\"hour\"].hist(bins=24)\n",
        "plt.xlabel(\"Hour of day\")\n",
        "plt.ylabel(\"Number of logon/logoff events\")\n",
        "plt.title(\"Distribution of logon/logoff events by hour\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iybyYgdF2ml"
      },
      "outputs": [],
      "source": [
        "logon_df = logon.copy()\n",
        "devices_df = devices.copy()\n",
        "emails_df = emails.copy()\n",
        "files_df = files.copy()\n",
        "\n",
        "\n",
        "logon_df = logon_df.rename(columns={\"date\": \"timestamp\"})\n",
        "devices_df = devices_df.rename(columns={\"date\": \"timestamp\"})\n",
        "emails_df = emails_df.rename(columns={\"date\": \"timestamp\"})\n",
        "files_df = files_df.rename(columns={\"date\": \"timestamp\"})\n",
        "\n",
        "for df in [logon_df, devices_df, emails_df, files_df]:\n",
        "    df[\"date_only\"] = df[\"timestamp\"].dt.date\n",
        "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
        "    df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n",
        "\n",
        "# helper: count night/odd-hour events\n",
        "def count_late_hours(hours: pd.Series, start=0, end=6, night_start=20) -> int:\n",
        "    \"\"\"\n",
        "    Count events between [0,6) or [20,24).\n",
        "    \"\"\"\n",
        "    return ((hours < end) | (hours >= night_start)).sum()\n",
        "\n",
        "logon_daily = (\n",
        "    logon_df.groupby([\"user\", \"date_only\"])\n",
        "    .agg(\n",
        "        total_logon_events=(\"activity\", \"count\"),\n",
        "        unique_logon_pcs=(\"pc\", pd.Series.nunique),\n",
        "        night_logon_events=(\"hour\", count_late_hours),\n",
        "        min_logon_time=(\"timestamp\", \"min\"),\n",
        "        max_logon_time=(\"timestamp\", \"max\"),\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "logon_daily[\"work_span_hours\"] = (\n",
        "    (logon_daily[\"max_logon_time\"] - logon_daily[\"min_logon_time\"]).dt.total_seconds()\n",
        "    / 3600.0\n",
        ")\n",
        "\n",
        "devices_daily = (\n",
        "    devices_df.groupby([\"user\", \"date_only\"])\n",
        "    .agg(\n",
        "        total_device_events=(\"activity\", \"count\"),\n",
        "        device_connects=(\"activity\", lambda s: (s == \"Connect\").sum()),\n",
        "        unique_device_pcs=(\"pc\", pd.Series.nunique),\n",
        "        night_device_events=(\"hour\", count_late_hours),\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "emails_daily = (\n",
        "    emails_df.groupby([\"user\", \"date_only\"])\n",
        "    .agg(\n",
        "        total_email_events=(\"timestamp\", \"count\"),\n",
        "        unique_email_pcs=(\"pc\", pd.Series.nunique),\n",
        "        night_email_events=(\"hour\", count_late_hours),\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "email_recip = emails_df.copy()\n",
        "email_recip[\"recip_blob\"] = (\n",
        "    email_recip[\"to\"].fillna(\"\").astype(str) + \";\" +\n",
        "    email_recip[\"cc\"].fillna(\"\").astype(str) + \";\" +\n",
        "    email_recip[\"bcc\"].fillna(\"\").astype(str)\n",
        ")\n",
        "email_recip[\"recipient\"] = email_recip[\"recip_blob\"].str.replace(\",\", \";\").str.split(\";\")\n",
        "email_recip = email_recip.explode(\"recipient\")\n",
        "email_recip[\"recipient\"] = email_recip[\"recipient\"].astype(str).str.strip()\n",
        "email_recip = email_recip[email_recip[\"recipient\"] != \"\"]\n",
        "\n",
        "email_recip_daily = (\n",
        "    email_recip.groupby([\"user\", \"date_only\"])\n",
        "    .agg(unique_email_recipients=(\"recipient\", pd.Series.nunique))\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "emails_daily = emails_daily.merge(email_recip_daily, on=[\"user\", \"date_only\"], how=\"left\")\n",
        "\n",
        "files_df[\"is_copy\"] = files_df[\"activity\"].astype(str).str.contains(\"copy\", case=False, na=False)\n",
        "\n",
        "files_daily = (\n",
        "    files_df.groupby([\"user\", \"date_only\"])\n",
        "    .agg(\n",
        "        total_file_events=(\"activity\", \"count\"),\n",
        "        unique_file_pcs=(\"pc\", pd.Series.nunique),\n",
        "        unique_files_touched=(\"filename\", pd.Series.nunique),\n",
        "        file_copy_events=(\"is_copy\", \"sum\"),\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "files_daily = files_daily[[\"user\", \"date_only\", \"total_file_events\", \"unique_files_touched\", \"file_copy_events\"]]\n",
        "\n",
        "daily = logon_daily.merge(\n",
        "    devices_daily, on=[\"user\", \"date_only\"], how=\"outer\"\n",
        ").merge(\n",
        "    emails_daily, on=[\"user\", \"date_only\"], how=\"outer\"\n",
        ").merge(\n",
        "    files_daily, on=[\"user\", \"date_only\"], how=\"outer\"\n",
        ")\n",
        "\n",
        "numeric_cols = daily.select_dtypes(include=[np.number]).columns\n",
        "daily[numeric_cols] = daily[numeric_cols].fillna(0)\n",
        "\n",
        "print(\"Daily user-day table shape:\", daily.shape)\n",
        "display(daily.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P2szOM8F6-0"
      },
      "outputs": [],
      "source": [
        "# feature columns for anomaly detection\n",
        "feature_cols = [\n",
        "    \"total_logon_events\",\n",
        "    \"unique_logon_pcs\",\n",
        "    \"night_logon_events\",\n",
        "    \"work_span_hours\",\n",
        "\n",
        "    \"total_device_events\",\n",
        "    \"device_connects\",\n",
        "    \"unique_device_pcs\",\n",
        "    \"night_device_events\",\n",
        "\n",
        "    \"total_email_events\",\n",
        "    \"unique_email_pcs\",\n",
        "    \"night_email_events\",\n",
        "    \"unique_email_recipients\",\n",
        "\n",
        "    \"total_file_events\",\n",
        "    \"unique_files_touched\",\n",
        "    \"file_copy_events\",\n",
        "]\n",
        "\n",
        "print(\"Using feature columns:\", feature_cols)\n",
        "\n",
        "X = daily[feature_cols].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "iso = IsolationForest(\n",
        "    n_estimators=200,\n",
        "    contamination=0.02,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "iso.fit(X_scaled)\n",
        "\n",
        "daily[\"anomaly_score\"] = iso.decision_function(X_scaled)\n",
        "daily[\"anomaly_label\"] = iso.predict(X_scaled)\n",
        "\n",
        "num_anomalies = (daily[\"anomaly_label\"] == -1).sum()\n",
        "print(\"Number of anomalous user-days:\", num_anomalies, \"out of\", len(daily))\n",
        "\n",
        "display(daily.head())\n",
        "print(\"daily.shape:\", daily.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIo-ncWrNwSK"
      },
      "outputs": [],
      "source": [
        "# sort anomalies by most anomalous (lowest score)\n",
        "anomalies = (\n",
        "    daily[daily[\"anomaly_label\"] == -1]\n",
        "    .sort_values(\"anomaly_score\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(\"Top 20 anomalies (user-day rows):\")\n",
        "display(anomalies[[\"user\", \"date_only\", \"anomaly_score\"] + feature_cols].head(20))\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "daily[\"anomaly_score\"].hist(bins=50)\n",
        "plt.xlabel(\"IsolationForest anomaly score\")\n",
        "plt.ylabel(\"Count of user-days\")\n",
        "plt.title(\"Distribution of anomaly scores\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "if len(anomalies) > 0:\n",
        "    sus_user = anomalies[\"user\"].iloc[0]\n",
        "    print(\"Inspecting user:\", sus_user)\n",
        "\n",
        "    sus_user_days = daily[daily[\"user\"] == sus_user].sort_values(\"date_only\")\n",
        "\n",
        "    display(\n",
        "        sus_user_days[\n",
        "            [\"user\", \"date_only\", \"anomaly_score\", \"anomaly_label\"] + feature_cols\n",
        "        ].tail(30)\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(sus_user_days[\"date_only\"], sus_user_days[\"anomaly_score\"], marker=\"o\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Anomaly score\")\n",
        "    plt.title(f\"Anomaly scores over time for user {sus_user}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No anomalies detected with current contamination setting.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxyLCI4uQaUE"
      },
      "outputs": [],
      "source": [
        "search_user = \"CDE1846\"\n",
        "\n",
        "user_data = daily[daily[\"user\"].str.contains(search_user, case=False, na=False)]\n",
        "\n",
        "if len(user_data) == 0:\n",
        "    print(f\"No users found containing '{search_user}'.\")\n",
        "else:\n",
        "    print(f\"Showing records for user(s) matching: {search_user}\")\n",
        "    display(\n",
        "        user_data.sort_values(\"anomaly_score\")[\n",
        "            [\"user\", \"date_only\", \"anomaly_score\", \"anomaly_label\"] + feature_cols\n",
        "        ].head(30)\n",
        "    )\n",
        "\n",
        "    # plot anomaly history for each matching user\n",
        "    for u in user_data['user'].unique():\n",
        "        tmp = user_data[user_data[\"user\"] == u].sort_values(\"date_only\")\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.plot(tmp[\"date_only\"], tmp[\"anomaly_score\"], marker=\"o\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.ylabel(\"Anomaly Score\")\n",
        "        plt.title(f\"Anomaly scores over time â€” {u}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily[\"anomaly_rank\"] = daily[\"anomaly_score\"].rank(method=\"min\", ascending=True).astype(int)\n",
        "\n",
        "n = len(daily)\n",
        "daily[\"anomaly_percentile\"] = (daily[\"anomaly_rank\"] - 1) / (n - 1) if n > 1 else 0.0\n",
        "daily[\"anomaly_percentile_100\"] = 100.0 * daily[\"anomaly_percentile\"]\n",
        "\n",
        "# date range filter\n",
        "start_date = \"2011-04-21\"\n",
        "end_date   = \"2011-04-25\"\n",
        "\n",
        "start_date = pd.to_datetime(start_date).date()\n",
        "end_date   = pd.to_datetime(end_date).date()\n",
        "\n",
        "daily_range = daily[(daily[\"date_only\"] >= start_date) & (daily[\"date_only\"] <= end_date)].copy()\n",
        "\n",
        "search_user = \"CDE1846\"\n",
        "if search_user is not None:\n",
        "    daily_range = daily_range[daily_range[\"user\"].str.contains(search_user, case=False, na=False)].copy()\n",
        "    print(\"Rows after user filter:\", len(daily_range))\n",
        "\n",
        "# display the most anomalous rows in that date range\n",
        "display_cols = [\"user\", \"date_only\", \"anomaly_score\", \"anomaly_label\",\n",
        "                \"anomaly_rank\", \"anomaly_percentile_100\"] + feature_cols\n",
        "\n",
        "display(daily_range.sort_values([\"anomaly_percentile_100\", \"anomaly_score\"])[display_cols].head(50))"
      ],
      "metadata": {
        "id": "46MZ13am3KDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily[\"anomaly_rank\"] = daily[\"anomaly_score\"].rank(method=\"min\", ascending=True).astype(int)\n",
        "\n",
        "n = len(daily)\n",
        "daily[\"anomaly_percentile\"] = (daily[\"anomaly_rank\"] - 1) / (n - 1) if n > 1 else 0.0\n",
        "daily[\"anomaly_percentile_100\"] = 100.0 * daily[\"anomaly_percentile\"]\n",
        "\n",
        "# date range filter\n",
        "start_date = \"2010-08-12\"\n",
        "end_date   = \"2010-08-12\"\n",
        "\n",
        "start_date = pd.to_datetime(start_date).date()\n",
        "end_date   = pd.to_datetime(end_date).date()\n",
        "\n",
        "daily_range = daily[(daily[\"date_only\"] >= start_date) & (daily[\"date_only\"] <= end_date)].copy()\n",
        "\n",
        "search_user = \"PLJ1771\"\n",
        "if search_user is not None:\n",
        "    daily_range = daily_range[daily_range[\"user\"].str.contains(search_user, case=False, na=False)].copy()\n",
        "    print(\"Rows after user filter:\", len(daily_range))\n",
        "\n",
        "# display the most anomalous rows in the date range\n",
        "display_cols = [\"user\", \"date_only\", \"anomaly_score\", \"anomaly_label\",\n",
        "                \"anomaly_rank\", \"anomaly_percentile_100\"] + feature_cols\n",
        "\n",
        "display(daily_range.sort_values([\"anomaly_percentile_100\", \"anomaly_score\"])[display_cols].head(50))"
      ],
      "metadata": {
        "id": "DHbUb1Uv2Brm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V6E1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}